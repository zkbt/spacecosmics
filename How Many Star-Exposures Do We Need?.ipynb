{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a star whose true flux is 1, and we make $N$ flux measurements $f_{i}$ of it, and each of those measurements has a constant per-binned exposure uncertainty $\\sigma_i = \\sigma$, so $f_{i}$ scatters around 1. We can make an estimate of $\\sigma \\approx \\sigma_e$ from the data, via\n",
    "\n",
    "$$ \\sigma_e = \\frac{1}{N}\\sum^{N}_{i} \\left(f_i - 1\\right)^2$$\n",
    "\n",
    "But, because this is a measurement made from a finite amount of noisy data, there will be an uncertainty associated with the estimator $\\sigma_e$. That uncertainty works out to be (I think):\n",
    "\n",
    "$$ \\sigma_{\\sigma_e} = \\frac{\\sigma}{\\sqrt{N}} \\approx \\frac{\\sigma_e}{\\sqrt{N}} $$.\n",
    "\n",
    "For example, from samples in our data we could determine that a TESS star (on some timescale) has an RMS of $\\sigma_e \\pm \\sigma_{\\sigma_e} = 200 \\pm 20~ppm$. Generally, we'll care about the fractional uncertainty on our estimate of $\\sigma$, which looks like\n",
    "\n",
    "$$\\sigma_{\\sigma_e}/\\sigma_{e} = \\frac{1}{\\sqrt{N}}$$\n",
    "\n",
    "This means that if we have $N = 100$ samples (binned exposures), then we can estimate $\\sigma$ with a precision of 10%. We can get to a given value of $N$, for stars within a narrow magnitude range where we expect $\\sigma$ to similar, through any combination of more exposures ($N_{exposures}$) or more stars averaged together ($N_{stars}$), with\n",
    "\n",
    "$$N = N_{exposures} \\times N_{stars}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To reach a fractional uncertainty of 1.0% on the estimated RMS,\n",
      "we need 10000 star-exposures per bin. To cover 10 magnitudes in\n",
      "brightness in bins of 0.2, we need 500000 star-hours. This can\n",
      "be achieved in 1.0 days as 720 (2.0 minute) exposures on 694 postage stamps\n",
      "or 48 (30.0 minute) exposures on 10417 FFI stars.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fractionalprecision = 0.01 \n",
    "Nperbin = 1/fractionalprecision**2\n",
    "magnitudespan = 10\n",
    "magnitudebin = 0.2\n",
    "Nbins = magnitudespan/magnitudebin\n",
    "Ntotal = Nbins*Nperbin\n",
    "days = 1.0\n",
    "\n",
    "postagecadence = 2.0\n",
    "fficadence = 30.0\n",
    "postage = postagecadence/60.0/24.0\n",
    "ffi = fficadence/60.0/24.0\n",
    "Nexposurespostage = days/postage\n",
    "Nstarspostage = Ntotal/Nexposurespostage\n",
    "\n",
    "Nexposuresffis = days/ffi\n",
    "Nstarsffis = Ntotal/Nexposuresffis\n",
    "\n",
    "s = \"\"\"\n",
    "To reach a fractional uncertainty of {fractionalprecision:.1%} on the estimated RMS,\n",
    "we need {Nperbin:.0f} star-exposures per bin. To cover {magnitudespan} magnitudes in\n",
    "brightness in bins of {magnitudebin}, we need {Ntotal:.0f} star-exposures. This can\n",
    "be achieved in {days} days as {Nexposurespostage:.0f} ({postagecadence} minute) exposures on {Nstarspostage:.0f} postage stamps\n",
    "or {Nexposuresffis:.0f} ({fficadence} minute) exposures on {Nstarsffis:.0f} FFI stars.\n",
    "\n",
    "\n",
    "\"\"\".format(**locals())\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
